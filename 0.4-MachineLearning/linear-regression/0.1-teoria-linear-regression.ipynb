{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ¿Qué es el R-cuadrado? \n",
    "\n",
    "El R-cuadrado es una medida estadística de qué tan cerca están los datos de la línea de regresión ajustada. También se conoce como coeficiente de determinación, o coeficiente de determinación múltiple si se trata de regresión múltiple.\n",
    "\n",
    "La definición de R-cuadrado es bastante sencilla: es el porcentaje de la variación en la variable de respuesta que es explicado por un modelo lineal. Es decir:\n",
    "\n",
    "R-cuadrado = Variación explicada / variación total\n",
    "\n",
    "El R-cuadrado siempre está entre 0 y 100%:\n",
    "\n",
    "- 0% indica que el modelo no explica ninguna porción de la variabilidad de los datos de respuesta en torno a su media.\n",
    "- 100% indica que el modelo explica toda la variabilidad de los datos de respuesta en torno a su media.\n",
    "\n",
    "### Limitaciones claves del R-Cuadrado\n",
    "- El R-cuadrado no puede determinar si las estimaciones y predicciones de los coeficientes están sesgadas, y es por eso que se deben examinar las gráficas de residuos.\n",
    "\n",
    "- El R-cuadrado no indica si un modelo de regresión es adecuado. Se puede tener un valor bajo del R-cuadrado para un modelo adecuado o un valor alto del R-cuadrado para un modelo que no se ajusta a los datos.\n",
    "\n",
    "### R-cuadrado ajustado\n",
    "\n",
    "- R2 ajustado es una medida corregida de bondad de ajuste (precisión de modelo) para los modelos lineales. Identifica el porcentaje de varianza en el campo de destino que se explica por la entrada o las entradas.\n",
    "\n",
    "- R2 tiende a estimar de forma optimista el ajuste de la regresión lineal. Siempre aumenta a medida que el número de efectos se incluye en el modelo. R2 ajustado intenta corregir esta sobrestimación. R2 ajustado puede disminuir si un efecto específico no mejora el modelo.\n",
    "\n",
    "- R cuadrado ajustado se calcula dividiendo el error cuadrático medio residual por el error cuadrático total (que es la varianza de muestreo del campo objetivo). A continuación, al resultado se le resta 1.\n",
    "\n",
    "- R2 ajustado es siempre menor que o igual a R2. Un valor de 1 indica un modelo que predice perfectamente los valores en el campo de destino. Un valor que es menor o igual que 0 indica un modelo que no tiene ningún valor predictivo. En el mundo real, R2 ajustado se encuentra entre estos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. F-statistic \n",
    "\n",
    "La F-statistic es una medida que se usa en los análisis de regresión para evaluar si el modelo en su totalidad tiene una relación significativa con la variable dependiente. Básicamente, ayuda a determinar si las variables independientes (las que están explicando el modelo) realmente están aportando información valiosa para predecir la variable dependiente, o si podría ser que todo sea por azar.\n",
    "\n",
    "- Un valor más alto sugiere que las variables del modelo están haciendo un buen trabajo al explicar la variación en la variable dependiente.\n",
    "\n",
    "- **Prob (F-statistic)**: Esta es la probabilidad asociada con la F-statistic, **cuanto más cercano a 0 sea el valor de \"Prob (F-statistic)\" mejor**, más confianza tenemos de que las variables independientes explican significativamente la variación en la variable dependiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. AIC (Criterio de información de Akaike):\n",
    "- El AIC busca equilibrar el ajuste del modelo y su simplicidad.\n",
    "- Un AIC más bajo significa que el modelo es mejor. Sin embargo, esto no significa que un AIC bajo sea siempre lo mejor, ya que puede implicar que el modelo es más complejo (más variables incluidas), lo que podría llevar a sobreajuste.\n",
    "\n",
    "### 4. BIC (Criterio de información Bayesiano):\n",
    "- El BIC también penaliza los modelos complejos, pero lo hace de manera más fuerte que el AIC.\n",
    "- Al igual que el AIC, un BIC más bajo es mejor. Sin embargo, el BIC tiende a favorecer modelos más simples (menos parámetros) que el AIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Coeficientes y Significación\n",
    "Cada fila en esta sección representa una variable independiente en el modelo, y la columna más importante aquí es P>|t|, que muestra el valor p de la prueba de hipótesis para cada coeficiente:\n",
    "\n",
    "-  Si el p-value es menor a 0.05, se puede decir que la variable es significativa.\n",
    "\n",
    "- Si es mayor a 0.05, la variable no es significativa y podría no tener un impacto claro en el modelo.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "**Coeficientes:**\n",
    "\n",
    "- **const (intercepto):45.1925** → El valor promedio de MEDV cuando todas las variables independientes son 0.\n",
    "- **CRIM: -0.1144 (p-value: 0.001)** → El coeficiente es negativo, lo que indica que un aumento en la tasa de criminalidad (CRIM) se asocia con una disminución en el valor de las viviendas. Es significativo.\n",
    "- **ZN: 0.0571 (p-value: 0.001)** → Un aumento en la proporción de terrenos residenciales (ZN) está asociado con un aumento en MEDV. Es significativo.\n",
    "- **INDUS: 0.0383 (p-value: 0.590)** → No es significativo.\n",
    "- **CHAS: 2.4285 (p-value: 0.010)** → Si una vivienda está cerca del río Charles, aumenta el valor de la vivienda en 2.4285. Es significativo.\n",
    "- **NOX: -21.2326 (p-value: 0.000)** → Un aumento en el óxido de nitrógeno (NOX) reduce considerablemente el valor de la vivienda. Es altamente significativo.\n",
    "- **RM: 2.8772 (p-value: 0.000)** → A mayor cantidad de habitaciones (RM), mayor es el valor de la vivienda. Es altamente significativo.\n",
    "- **AGE: 0.0069 (p-value: 0.662)** → No es significativo.\n",
    "- **DIS: -1.4716 (p-value: 0.000)** → Mayor distancia a los centros de empleo reduce el valor de la vivienda. Es significativo.\n",
    "- **RAD: 0.3058 (p-value: 0.000)** → Un coeficiente positivo y significativo; el índice de accesibilidad a carreteras radiales tiene un efecto positivo en el valor de la vivienda.\n",
    "- **TAX: -0.0107 (p-value: 0.022)** → El coeficiente es negativo, lo que sugiere que los impuestos altos (TAX) reducen el valor de las viviendas. Es significativo.\n",
    "- **PTRATIO: -0.9961 (p-value: 0.000)** → Un mayor índice de estudiantes por profesor (PTRATIO) reduce el valor de las viviendas. Es altamente significativo.\n",
    "- **B: 0.0063 (p-value: 0.052)** → Casi significativo (p = 0.052). Indica que cuanto mayor sea este índice (que mide la proporción de la población negra), mayor será el valor de la vivienda.\n",
    "- **LSTAT: -0.5574 (p-value: 0.000)** → A mayor porcentaje de personas con bajos recursos, menor es el valor de la vivienda. Es altamente significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. El Durbin-Watson (DW) \n",
    "Es una estadística que se utiliza para detectar la autocorrelación en los residuos (errores) de un modelo de regresión. La autocorrelación ocurre cuando los errores no son independientes entre sí, lo cual puede afectar la validez de los resultados del modelo.\n",
    "\n",
    "**Interpretación básica:**\n",
    "El estadístico de Durbin-Watson tiene un rango de valores entre 0 y 4:\n",
    "\n",
    "- DW ≈ 2: Esto indica que no hay autocorrelación en los residuos. Es el valor ideal y el que buscas en un buen modelo.\n",
    "- DW < 2: Indica que hay autocorrelación positiva en los residuos, lo que significa que los errores tienden a estar correlacionados en el mismo sentido (si un error es positivo, el siguiente también tiende a ser positivo).\n",
    "- DW > 2: Indica que hay autocorrelación negativa, lo que significa que los errores tienden a alternarse entre positivo y negativo.\n",
    "\n",
    "**Guía de interpretación de valores:**\n",
    "- DW ≈ 2: No hay autocorrelación.\n",
    "- DW < 1.5: Existe autocorrelación positiva.\n",
    "- DW > 2.5: Existe autocorrelación negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Cond. NO (Número de condición)\n",
    "Es una métrica que indica el nivel de multicolinealidad entre las variables independientes (predictoras) en un modelo de regresión. La multicolinealidad ocurre cuando dos o más variables independientes están altamente correlacionadas, lo que puede causar problemas en la estimación de los coeficientes del modelo.\n",
    "\n",
    "**Interpretación:**\n",
    "- **Cond. No. < 10:** No hay multicolinealidad significativa, el modelo está bien.\n",
    "- **Cond. No. entre 10 y 30:** Hay una moderada multicolinealidad, lo cual puede comenzar a afectar las estimaciones.\n",
    "- **Cond. No. > 30:** Hay una alta multicolinealidad, lo que sugiere que algunos de los coeficientes del modelo pueden no ser fiables debido a la relación fuerte entre las variables independientes.\n",
    "\n",
    "**Consecuencias de un alto Número de Condición:**\n",
    "- Coeficientes inestables: Los coeficientes pueden variar mucho si cambias ligeramente los datos.\n",
    "- Interpretación difícil: Es difícil interpretar los efectos de las variables individuales porque están demasiado correlacionadas entre sí.\n",
    "- Menor precisión: Las predicciones del modelo pueden ser menos precisas.\n",
    "\n",
    "**Soluciones para multicolinealidad:**\n",
    "- Eliminar variables altamente correlacionadas.\n",
    "- Transformar algunas variables (por ejemplo, crear combinaciones lineales de variables que están correlacionadas).\n",
    "- Usar técnicas como la regresión Ridge o la regresión Lasso, que están diseñadas para manejar multicolinealidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Assumption "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
