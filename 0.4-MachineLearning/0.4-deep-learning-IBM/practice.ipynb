{"cells":[{"cell_type":"markdown","id":"89d849b8-6f5e-43dd-a0b9-e04d00b06b17","metadata":{},"source":["# Machine Learning Foundation\n","\n","## Course 5, Part d: Keras Intro LAB\n"]},{"cell_type":"markdown","id":"621dcda1-02fd-47c6-8e88-e28711cc579e","metadata":{},"source":["## Using Keras to Build and Train Neural Networks\n"]},{"cell_type":"markdown","id":"549a1a40-f563-4633-b1c0-83c1e6c7ba60","metadata":{},"source":["In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n","\n","## UCI Pima Diabetes Dataset\n","\n","* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n","\n","\n","### Attributes: (all numeric-valued)\n","   1. Number of times pregnant\n","   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","   3. Diastolic blood pressure (mm Hg)\n","   4. Triceps skin fold thickness (mm)\n","   5. 2-Hour serum insulin (mu U/ml)\n","   6. Body mass index (weight in kg/(height in m)^2)\n","   7. Diabetes pedigree function\n","   8. Age (years)\n","   9. Class variable (0 or 1)\n"]},{"cell_type":"markdown","id":"81bbd5b2-50ec-4974-b2cc-1daa2a9b1465","metadata":{},"source":["The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome.\n"]},{"cell_type":"code","execution_count":1,"id":"35e5824c-f973-4fa3-8c2f-52bb38972bda","metadata":{},"outputs":[],"source":["#Setup\n","import warnings\n","import skillsnetwork\n","\n","warnings.filterwarnings(\"ignore\")\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":2,"id":"74b792f8-de67-4cc9-a823-2bebea21259b","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-28 11:20:58.868313: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["## Import Keras objects for Deep Learning\n","from keras.models  import Sequential\n","from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n","from keras.optimizers import Adam, SGD, RMSprop"]},{"cell_type":"code","execution_count":3,"id":"014fca65-e02a-428e-98bb-bdc21ca9bc15","metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26f099160cb14afeb27d21a4cbee639c","version_major":2,"version_minor":0},"text/plain":["Downloading diabetes.csv:   0%|          | 0/23873 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saved to '.'\n"]}],"source":["## Load in the data set \n","await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module2/L2/diabetes.csv\", overwrite=True)\n","\n","names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n","         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n","diabetes_df = pd.read_csv('./diabetes.csv', names=names, header=0)"]},{"cell_type":"markdown","id":"62d05a10-e650-4e03-a8f5-c94fa6dd7483","metadata":{},"source":["Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n","## Exercise 1: Get a baseline performance using Random Forest\n","To begin, and get a baseline for classifier performance:\n","1. Train a Random Forest model with 200 trees on the training data.\n","2. Calculate the accuracy and roc_auc_score of the predictions.\n"]},{"cell_type":"markdown","id":"4d26127b-39de-4e95-bff0-57eeb595fec0","metadata":{},"source":["## Build a Single Hidden Layer Neural Network\n","\n","We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes.\n"]},{"cell_type":"markdown","id":"e7216067-60d8-47da-96aa-5a7df8698475","metadata":{},"source":["### Comprehension question:\n","Why do we have 121 parameters?  Does that make sense?\n","\n","Let's fit our model for 200 epochs.\n"]},{"cell_type":"markdown","id":"509bee8e-fba2-4404-b5e2-3d9cd02015f4","metadata":{},"source":["There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC.\n"]},{"cell_type":"markdown","id":"f379ec93-5fa8-4aac-9549-9d2b2ca310e1","metadata":{},"source":["Let's look at the `run_hist_1` object that was created, specifically its `history` attribute.\n"]},{"cell_type":"markdown","id":"8c7c1a07-26a3-4166-9747-d635f297c3af","metadata":{},"source":["Let's plot the training loss and the validation loss over the different epochs and see how it looks.\n"]},{"cell_type":"markdown","id":"175a16d4-a281-45c6-afca-2152708fab18","metadata":{},"source":["Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs.\n"]},{"cell_type":"markdown","id":"77f3da73-debd-415a-b590-39dc846ef4e2","metadata":{},"source":["Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?\n"]},{"cell_type":"markdown","id":"b0ef5fb2-2181-45d5-9d5f-5c09f0d3b048","metadata":{},"source":["## Exercise 2\n","For this exercise, do the following in the cells below:\n","- Build a model with two hidden layers, each with 6 nodes\n","- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n","- Use a learning rate of .003 and train for 1500 epochs\n","- Graph the trajectory of the loss functions, accuracy on both train and test set\n","- Plot the roc curve for the predictions\n","\n","Experiment with different learning rates, numbers of epochs, and network structures\n"]},{"cell_type":"markdown","id":"bd196ea3-bd9d-4fef-af32-0861c4475e69","metadata":{},"source":["---\n","### Machine Learning Foundation (C) 2020 IBM Corporation\n"]}],"metadata":{"kernelspec":{"display_name":"data_science_path","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"prev_pub_hash":"30b1fc428859ab438b764ed616fdf71d5544d8828f0effc96e9c74ccabbdc852"},"nbformat":4,"nbformat_minor":4}
